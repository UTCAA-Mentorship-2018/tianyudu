{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from constants import *\n",
    "from core.data.data_proc import *\n",
    "from core.tools.roc_visualize import *\n",
    "from ui_control import *\n",
    "\n",
    "from feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set avaiable: \n",
      "{'CLOUD': 'https://s3.us-east-2.amazonaws.com/tianyudu/kaggle/application_train.csv',\n",
      " 'DRIVE': '/Volumes/Intel/Data/UTCAA-Mentorship-2018/application_train.csv',\n",
      " 'EC2': '/home/ec2-user/environment/mentor_2018/data/application_train.csv',\n",
      " 'EC2SERVER': '/home/ec2-user/data/application_train.csv',\n",
      " 'MAC': '/Users/tianyudu/Documents/Activities/UTCAA-Mentorship-2018/data/application_train.csv'}\n",
      "Note that file directory selection is case senstive.\n",
      "Where is the dataset? [C: customize]>>> c\n",
      "Dataset dir >>> /home/ec2-user/data/bureau.csv\n",
      "Loading dataset from local file...\n",
      "Raw data shape: (1716428, 17)\n",
      "Data shape after column drop(threshold: 0.1): (1716428, 12)\n",
      "        num of features left 12\n",
      "Observation lost after ignoring obs w/ nan attributes:  6.150 %\n",
      "Data shape after ignoring obs w/ nan attributes: (1610871, 12)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Oops, target not found in dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0c0ee24982d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdrop_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDROP_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     drop_columns=DROP_COLUMNS)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SK_ID_CURR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/tianyudu/core/data/data_proc.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_dir, drop_columns, drop_threshold)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_na_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m\"TARGET\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Oops, target not found in dataset.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Oops, target not found in dataset."
     ]
    }
   ],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== GBM Setup ========\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    scaled_splited[\"X_train\"],\n",
    "    label=splited[\"y_train\"],\n",
    "    feature_name=list(X.columns.astype(str))\n",
    ")\n",
    "\n",
    "validation_data = lgb.Dataset(\n",
    "    scaled_splited[\"X_val\"],\n",
    "    label=splited[\"y_val\"],\n",
    "    reference=train_data,\n",
    "    feature_name=list(X.columns.astype(str))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": [\"binary_logloss\", \"auc\"],\n",
    "    \"sub_feature\": 0.5,\n",
    "    \"num_leaves\": 64,\n",
    "    \"min_data\": 50,\n",
    "    \"max_depth\": 25,\n",
    "    \"max_bin\": 512\n",
    "}\n",
    "\n",
    "evals_result = dict()\n",
    "\n",
    "NBR = int(input(\"Number of boosting rounds >>> \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lgb.train(\n",
    "    train_set=train_data,\n",
    "    params=params,\n",
    "    num_boost_round=NBR,\n",
    "    valid_sets=[train_data, validation_data],\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
